{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis of HackerNews Posts\n",
    "\n",
    "This is a guided project provided by [Dataquest.io](https://dataquest.io/). In this project we will be analysing the posts of [HackerNews](https://news.ycombinator.com/) Platform, a popular site where technology related stories (or 'posts') are voted and commented upon.It will answer the following questions:\n",
    "\n",
    "-   Do Ask HN or Show HN receive more comments on average?<br>\n",
    "-   Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "where, <br>\n",
    "**Ask HN posts** = The questions on the HackerNews Community <br>\n",
    "**Show HN posts** = The posts to show community a project, product or something interesting. <br><br>\n",
    "It should be noted that the data set we're working with was reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "## Apart from what was covered in the guided project, following additional analysis was also performed:\n",
    "\n",
    "- Determining if show or ask posts receive more points on average\n",
    "- Finding the blockbuster (most popular) type of Post based on average points \n",
    "- Determining if posts created at a certain time are more likely to receive more points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "First we'll read and remove the headers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data With Headers:\n",
      "\n",
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n",
      "\n",
      "\n",
      "Headers:\n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "#reading the file and converting it into usable list of lists format\n",
    "read_file = reader(open(\"hacker_news.csv\"))\n",
    "hn = list(read_file)\n",
    "print(\"Data With Headers:\\n\")\n",
    "print(hn[:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "#first row contains headers\n",
    "headers = hn[0]\n",
    "print(\"Headers:\\n\")\n",
    "print(headers)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Headers from the dataset ( list of lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Without Headers:\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#excluding headers from dataset\n",
    "hn = hn[1:]\n",
    "print(\"Data Without Headers:\\n\")\n",
    "for i in hn[:5]:\n",
    "    print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions drawn from high level view of data\n",
    "\n",
    "We can see above that the data set contains the title of the posts, the number of comments for each post, and the date the post was created. Let's start by exploring the number of comments for each type of post.<br>\n",
    "\n",
    "# Extracting Ask HN and Show HN Posts\n",
    "First we will identify the posts starting with Ask HN or Show HN and categorize the data extracted into two different lists according to the type of post. Separating the list makes it easier to further analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Posts: 1744\n",
      "\n",
      "Show Posts: 1162\n",
      "\n",
      "Other Posts: 17194\n",
      "\n",
      "Sample data in Ask Posts list: \n",
      "\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']\n",
      "\n",
      "\n",
      "['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']\n",
      "\n",
      "\n",
      "['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']\n",
      "\n",
      "\n",
      "['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']\n",
      "\n",
      "\n",
      "Sample data in Show Posts list: \n",
      "\n",
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']\n",
      "\n",
      "\n",
      "['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']\n",
      "\n",
      "\n",
      "['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']\n",
      "\n",
      "\n",
      "['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts =[]\n",
    "show_posts =[]\n",
    "other_posts =[]\n",
    "\n",
    "#assign the posts according to their categorization from hn list of lists\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn') == True:\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn') == True:\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "#Printing number of posts of each types\n",
    "print(\"Ask Posts: \"+str(len(ask_posts))+\"\\n\")\n",
    "print(\"Show Posts: \"+str(len(show_posts))+\"\\n\")\n",
    "print(\"Other Posts: \"+str(len(other_posts))+\"\\n\")\n",
    "\n",
    "#Sample data in ask_posts and show_posts lists\n",
    "print(\"Sample data in Ask Posts list: \\n\")\n",
    "for i in ask_posts[:5]:\n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "print(\"Sample data in Show Posts list: \\n\")\n",
    "for i in show_posts[:5]:\n",
    "    print(i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the average number of comments for Ask HN and Show HN Posts\n",
    "Now that we separated ask posts and show posts into different lists, we'll calculate the average number of comments each type of post receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Number of Comments on Ask HN Category: 14.04\n",
      "\n",
      "Average Number of Comments on Show HN Category: 10.32\n",
      "\n",
      "Ask Posts recieve more comments on average\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "#calculating total number of comments of each category\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])    #row[4] contains number of comments in the dataset row\n",
    "    \n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"\\nAverage Number of Comments on Ask HN Category: \" + '{:0.2f}'.format(avg_ask_comments) +\"\\n\")\n",
    "print(\"Average Number of Comments on Show HN Category: \" + '{:0.2f}'.format(avg_show_comments) +\"\\n\")\n",
    "\n",
    "if(avg_ask_comments > avg_show_comments):\n",
    "    print(\"Ask Posts recieve more comments on average\")\n",
    "\n",
    "elif(avg_ask_comments == avg_show_comments):\n",
    "    print(\"Ask Posts has same comments on average as Show Posts\") \n",
    "    \n",
    "else:\n",
    "    print(\"Show Posts recieve more comments on average\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, Ask HN Posts in our sample recieve approximately 14 comments whereas, Show HN Posts recieve only 10. Since Ask posts are mre likely to recieve comments, we will focus our remaining analysis on these type of posts. \n",
    "\n",
    "\n",
    "# Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "Next, we'll determine if we can maximize the amount of comments an ask post receives by creating it at a certain time. First, we'll find the amount of ask posts created during each hour of day, along with the number of comments those posts received. Then, we'll calculate the average amount of comments ask posts created at each hour of the day receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by Hour:\n",
      "\n",
      "0 : 55\n",
      "1 : 60\n",
      "2 : 58\n",
      "3 : 54\n",
      "4 : 47\n",
      "5 : 46\n",
      "6 : 44\n",
      "7 : 34\n",
      "8 : 48\n",
      "9 : 45\n",
      "10 : 59\n",
      "11 : 58\n",
      "12 : 73\n",
      "13 : 85\n",
      "14 : 107\n",
      "15 : 116\n",
      "16 : 108\n",
      "17 : 100\n",
      "18 : 109\n",
      "19 : 110\n",
      "20 : 80\n",
      "21 : 109\n",
      "22 : 71\n",
      "23 : 68\n",
      "\n",
      " Comments by Hour:\n",
      "\n",
      "0 :  447\n",
      "1 :  683\n",
      "2 :  1381\n",
      "3 :  421\n",
      "4 :  337\n",
      "5 :  464\n",
      "6 :  397\n",
      "7 :  267\n",
      "8 :  492\n",
      "9 :  251\n",
      "10 :  793\n",
      "11 :  641\n",
      "12 :  687\n",
      "13 :  1253\n",
      "14 :  1416\n",
      "15 :  4477\n",
      "16 :  1814\n",
      "17 :  1146\n",
      "18 :  1439\n",
      "19 :  1188\n",
      "20 :  1722\n",
      "21 :  1745\n",
      "22 :  479\n",
      "23 :  543\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = dt.datetime.strptime(row[6],\"%m/%d/%Y %H:%M\")   #row[6] contains created date of comments\n",
    "    num_comments = int(row[4])  #row[4] contains number of comments\n",
    "    result_list.append([created_at,num_comments])\n",
    "    \n",
    "counts_by_hour ={} #contains the number of ask posts created during each hour of the day.\n",
    "comments_by_hour ={} #contains the corresponding number of comments ask posts created at each hour received\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    hr = date.hour\n",
    "    comments = row[1]\n",
    "    if hr not in counts_by_hour:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = comments \n",
    "    else:\n",
    "        counts_by_hour[hr] += 1\n",
    "        comments_by_hour[hr] += comments\n",
    "print(\"Counts by Hour:\\n\")\n",
    "for i in sorted(counts_by_hour.items()):\n",
    "    print(i[0],\":\",i[1])\n",
    "print(\"\\n Comments by Hour:\\n\")\n",
    "for i in sorted(comments_by_hour.items()):\n",
    "    print(i[0],\": \",i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Average number of Comments on Ask HN posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 5.5777777777777775],\n",
       " [13, 14.741176470588234],\n",
       " [10, 13.440677966101696],\n",
       " [14, 13.233644859813085],\n",
       " [16, 16.796296296296298],\n",
       " [23, 7.985294117647059],\n",
       " [12, 9.41095890410959],\n",
       " [17, 11.46],\n",
       " [15, 38.5948275862069],\n",
       " [21, 16.009174311926607],\n",
       " [20, 21.525],\n",
       " [2, 23.810344827586206],\n",
       " [18, 13.20183486238532],\n",
       " [3, 7.796296296296297],\n",
       " [5, 10.08695652173913],\n",
       " [19, 10.8],\n",
       " [1, 11.383333333333333],\n",
       " [22, 6.746478873239437],\n",
       " [8, 10.25],\n",
       " [4, 7.170212765957447],\n",
       " [0, 8.127272727272727],\n",
       " [6, 9.022727272727273],\n",
       " [7, 7.852941176470588],\n",
       " [11, 11.051724137931034]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for key in comments_by_hour:\n",
    "    avg_by_hour.append([key,(comments_by_hour[key]/counts_by_hour[key])])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and Printing values from List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, 15],\n",
       " [23.810344827586206, 2],\n",
       " [21.525, 20],\n",
       " [16.796296296296298, 16],\n",
       " [16.009174311926607, 21],\n",
       " [14.741176470588234, 13],\n",
       " [13.440677966101696, 10],\n",
       " [13.233644859813085, 14],\n",
       " [13.20183486238532, 18],\n",
       " [11.46, 17],\n",
       " [11.383333333333333, 1],\n",
       " [11.051724137931034, 11],\n",
       " [10.8, 19],\n",
       " [10.25, 8],\n",
       " [10.08695652173913, 5],\n",
       " [9.41095890410959, 12],\n",
       " [9.022727272727273, 6],\n",
       " [8.127272727272727, 0],\n",
       " [7.985294117647059, 23],\n",
       " [7.852941176470588, 7],\n",
       " [7.796296296296297, 3],\n",
       " [7.170212765957447, 4],\n",
       " [6.746478873239437, 22],\n",
       " [5.5777777777777775, 9]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments:\n",
      "\n",
      "15:00:00 -> 38.59 average comments per hour\n",
      "02:00:00 -> 23.81 average comments per hour\n",
      "20:00:00 -> 21.52 average comments per hour\n",
      "16:00:00 -> 16.80 average comments per hour\n",
      "21:00:00 -> 16.01 average comments per hour\n"
     ]
    }
   ],
   "source": [
    "# Sort the values and print the the 5 hours with the highest average comments.\n",
    "\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments:\\n\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = str(row[1])\n",
    "    hour = dt.datetime.strptime(hour,\"%H\") #converting hour into datetime object\n",
    "    hour = dt.datetime.strftime(hour, \"%H:%M:%S\") #formatting hour as per output requirement\n",
    "    comments = '{:0.2f}'.format(row[0])\n",
    "    template = \"{hour} -> {comments} average comments per hour\".format(hour =hour,comments = comments)\n",
    "    print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives the most comments per post on average is 15:00, with an average of 38.59 comments per post. There's about a 60% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "\n",
    "According to the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home), the timezone used is Eastern Time in the US. So, we could also write 15:00 as 3:00 pm est.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining whether ask posts or show posts recieve more points on average.\n",
    "\n",
    "### Calculating the total number of points accumulated by Ask HN and Show HN posts\n",
    "We will now find the total number of points corresponsding to Ask HN and Show HN posts. We will also prepare two dictionaries storing the points corresponding to each Ask and Show Post to find the **blockbuster** (post with highest number of points) post of each type.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of points accumulated by Ask HN Posts: 26268\n",
      "Total number of points accumulated by Show HN Posts: 32019\n"
     ]
    }
   ],
   "source": [
    "ask_posts_points ={} #dictionary to contain points corresponding to each ask post\n",
    "show_posts_points ={} #dictionary to contain points corresponding to each show post\n",
    "total_ask_points =0\n",
    "total_show_points = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_points += int(row[3]) #row[3] contains number of points of a post\n",
    "    ask_posts_points[int(row[3])] = row[1] #row[1] contains the name of the post \n",
    "    \n",
    "        \n",
    "for row in show_posts:\n",
    "    total_show_points += int(row[3]) #row[3] contains number of points of a post\n",
    "    show_posts_points[int(row[3])] = row[1]\n",
    "\n",
    "#print(ask_posts_points)\n",
    "#print(show_posts_points)\n",
    "print(\"Total number of points accumulated by Ask HN Posts:\",total_ask_points)\n",
    "print(\"Total number of points accumulated by Show HN Posts:\",total_show_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the average number of points corresponding to Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Points of Ask Posts:15.062\n",
      "Average Points of Show Posts:27.555\n",
      "Show HN Post category has 12.493 more points on an average than Ask HN Post category\n"
     ]
    }
   ],
   "source": [
    "avg_ask_posts_points = total_ask_points/len(ask_posts)\n",
    "avg_show_posts_points = total_show_points/len(show_posts)\n",
    "\n",
    "print(\"Average Points of Ask Posts:{:0.3f}\".format(avg_ask_posts_points))\n",
    "print(\"Average Points of Show Posts:{:0.3f}\".format(avg_show_posts_points))\n",
    "\n",
    "if avg_ask_posts_points > avg_show_posts_points:\n",
    "    print(\"Ask HN Post category has {:0.3f} more points on an average than Show HN Post category\".format(avg_ask_posts_points-avg_show_posts_points))\n",
    "else:\n",
    "    print(\"Show HN Post category has {:0.3f} more points on an average than Ask HN Post category\".format(avg_show_posts_points-avg_ask_posts_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Blockbuster Ask HN \n",
    "\n",
    "As Show HN Posts have more points on an average as compared to Ask HN Posts, we'll focus on the former to complete the points analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data in show_posts_points:\n",
      "\n",
      "[(26, 'Show HN: iPipeTo, Yeoman ui as a standalone composable cli tool'), (747, 'Show HN: Something pointless I made'), (1, 'Show HN: Raspberry PI Zero Docker/Swarm on QuickStart'), (3, 'Show HN: Decorating: Animated pulsed for your slow functions in Python'), (4, 'Show HN: ExtractorApp Convert Excel / CSV to API, SQL and Other Formats')]\n",
      "\n",
      "Blockbuster Post for type Show HN is \u001b[1mShow HN: New calendar app idea\u001b[0;0m having \u001b[1m825\u001b[0;0m points\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import operator\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "# print(\"Sample data in ask_posts_points:\\n\")\n",
    "# five_ask_posts =take(5,ask_posts_points.items())\n",
    "# print(five_ask_posts)\n",
    "\n",
    "print(\"Sample data in show_posts_points:\\n\")\n",
    "five_show_posts = take(5,show_posts_points.items())\n",
    "print(five_show_posts)\n",
    "\n",
    "#Finding the maximum point and post corresponding to it\n",
    "\n",
    "#max_ask_posts_point, max_point_ask_post = max(ask_posts_points.items(), key=operator.itemgetter(0))\n",
    "max_show_posts_point, max_point_show_post = max(show_posts_points.items(), key=operator.itemgetter(0))\n",
    "\n",
    "start = \"\\033[1m\" #bold starts\n",
    "end = \"\\033[0;0m\" #bold ends\n",
    "#print(\"\\n\\nBlockbuster Post for type Ask HN is \"+start+str(max_point_ask_post)+end+\" having \"+start+str(max_ask_posts_point)+end+\" points\")\n",
    "print(\"\\nBlockbuster Post for type Show HN is \"+start+str(max_point_show_post)+end+\" having \"+start+str(max_show_posts_point)+end+\" points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining if posts created at a certain time are more likely to receive more points\n",
    "\n",
    "Now we'll find out whether posts that are posted on the forum at a perticular time are more likely to recieve ore points or not.\n",
    "For this, we'll create a frequency dictionary for Show Posts which will map aggregated points to hours of the posts.\n",
    "### Finding the points recieved by Show Posts by Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show Posts points' mapping with hours:\n",
      "{14: 2187, 22: 1856, 18: 2215, 7: 494, 20: 1819, 5: 104, 16: 2634, 19: 1702, 15: 2228, 3: 679, 17: 2521, 6: 375, 2: 340, 13: 2438, 8: 519, 21: 866, 4: 386, 11: 1480, 12: 2543, 23: 1526, 9: 553, 1: 700, 10: 681, 0: 1173}\n"
     ]
    }
   ],
   "source": [
    "show_point_by_hour = {}\n",
    "show_counts_by_hour ={}\n",
    "\n",
    "for row in show_posts:\n",
    "    hour = dt.datetime.strptime(row[6],\"%m/%d/%Y %H:%M\").hour  # 3-> points , 6->datetime\n",
    "    points = int(row[3])\n",
    "    if hour in show_point_by_hour:\n",
    "        show_point_by_hour[hour]+=points\n",
    "        show_counts_by_hour += 1\n",
    "    else:\n",
    "        show_point_by_hour[hour] = points\n",
    "        show_counts_by_hour = 1\n",
    "        \n",
    "print(\"\\nShow Posts points' mapping with hours:\")\n",
    "print(show_point_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Average number of points per hour in a list of lists for Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 2.025],\n",
       " [22, 1.7185185185185186],\n",
       " [18, 2.050925925925926],\n",
       " [7, 0.45740740740740743],\n",
       " [20, 1.6842592592592593],\n",
       " [5, 0.0962962962962963],\n",
       " [16, 2.438888888888889],\n",
       " [19, 1.575925925925926],\n",
       " [15, 2.062962962962963],\n",
       " [3, 0.6287037037037037],\n",
       " [17, 2.3342592592592593],\n",
       " [6, 0.3472222222222222],\n",
       " [2, 0.3148148148148148],\n",
       " [13, 2.2574074074074075],\n",
       " [8, 0.48055555555555557],\n",
       " [21, 0.8018518518518518],\n",
       " [4, 0.3574074074074074],\n",
       " [11, 1.3703703703703705],\n",
       " [12, 2.35462962962963],\n",
       " [23, 1.412962962962963],\n",
       " [9, 0.5120370370370371],\n",
       " [1, 0.6481481481481481],\n",
       " [10, 0.6305555555555555],\n",
       " [0, 1.086111111111111]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_points_by_hour_show = []\n",
    "\n",
    "for key in show_point_by_hour:\n",
    "    avg_points_by_hour_show.append([key,show_point_by_hour[key]/show_counts_by_hour]) \n",
    "    \n",
    "avg_points_by_hour_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and printing values from list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.438888888888889, 16],\n",
       " [2.35462962962963, 12],\n",
       " [2.3342592592592593, 17],\n",
       " [2.2574074074074075, 13],\n",
       " [2.062962962962963, 15],\n",
       " [2.050925925925926, 18],\n",
       " [2.025, 14],\n",
       " [1.7185185185185186, 22],\n",
       " [1.6842592592592593, 20],\n",
       " [1.575925925925926, 19],\n",
       " [1.412962962962963, 23],\n",
       " [1.3703703703703705, 11],\n",
       " [1.086111111111111, 0],\n",
       " [0.8018518518518518, 21],\n",
       " [0.6481481481481481, 1],\n",
       " [0.6305555555555555, 10],\n",
       " [0.6287037037037037, 3],\n",
       " [0.5120370370370371, 9],\n",
       " [0.48055555555555557, 8],\n",
       " [0.45740740740740743, 7],\n",
       " [0.3574074074074074, 4],\n",
       " [0.3472222222222222, 6],\n",
       " [0.3148148148148148, 2],\n",
       " [0.0962962962962963, 5]]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped_list_av_pnt_hr = []\n",
    "for i in avg_points_by_hour_show:\n",
    "    swapped_list_av_pnt_hr.append([i[1],i[0]])\n",
    "    \n",
    "sorted_swapped_list_av_pnt_hr = sorted(swapped_list_av_pnt_hr, reverse=True)\n",
    "sorted_swapped_list_av_pnt_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours when Show HN Posts accumulated maximum points:\n",
      "\n",
      "16:00:00 -> 2.44 average points per hour\n",
      "12:00:00 -> 2.35 average points per hour\n",
      "17:00:00 -> 2.33 average points per hour\n",
      "13:00:00 -> 2.26 average points per hour\n",
      "15:00:00 -> 2.06 average points per hour\n"
     ]
    }
   ],
   "source": [
    "# Sort the values and print the the 5 hours with the highest average comments.\n",
    "\n",
    "print(\"Top 5 Hours when Show HN Posts accumulated maximum points:\\n\")\n",
    "\n",
    "for row in sorted_swapped_list_av_pnt_hr[:5]:\n",
    "    hour = str(row[1])\n",
    "    hour = dt.datetime.strptime(hour,\"%H\") #converting hour into datetime object\n",
    "    hour = dt.datetime.strftime(hour, \"%H:%M:%S\") #formatting hour as per output requirement\n",
    "    points = '{:0.2f}'.format(row[0])\n",
    "    template = \"{hour} -> {points} average points per hour\".format(hour =hour,points = points)\n",
    "    print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conclusion\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average. \n",
    "\n",
    "Also, an additional analysis was performed to find which type of post and the time recieves more points. Based on it, to maximise the points collected by posts, we'd recommend the post to be categorized as show post and created between 16:00 and 17:00 (4:00 pm - 5:00 pm est). The blockbuster post was also found using this points analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
